{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_denoise(brain_path,dwi_name,b_name,b0_min,para,method,data_out):\n",
    "    '''\n",
    "    Study_folder\n",
    "    tau_factor=para[1], patch_radius=para[2],pca_method='svd'\n",
    "    '''\n",
    "    from time import time\n",
    "    from dipy.denoise.localpca import localpca\n",
    "    from dipy.denoise.pca_noise_estimate import pca_noise_estimate\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    import nipype.interfaces.fsl as fsl #topup\n",
    "    from nipype.interfaces.fsl import TOPUP\n",
    "    from nipype.interfaces.fsl import ApplyTOPUP\n",
    "    from nipype.interfaces.fsl import Eddy\n",
    "    from nipype.interfaces.fsl import ExtractROI\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    from nibabel.nifti1 import Nifti1Header\n",
    "    from tqdm.notebook import tqdm\n",
    "    from dipy.io.image import load_nifti, save_nifti\n",
    "    from dipy.io import read_bvals_bvecs\n",
    "    import pandas as pd\n",
    "\n",
    "    for Study_folder in tqdm(brain_path):\n",
    "        os.chdir(Study_folder)\n",
    "        data_prefix = dwi_name\n",
    "        dwi_file = os.path.join(Study_folder,data_prefix+'.nii') # 4D diffusion data file name\n",
    "        img_data,img_affine,img = load_nifti(dwi_file,return_img=True)\n",
    "        bval = os.path.join(Study_folder,b_name+'.bval') # bval file name\n",
    "        bvec = os.path.join(Study_folder,b_name+'.bvec') # bvec file name\n",
    "        #------------\n",
    "        bvals, bvecs = read_bvals_bvecs(bval,bvec)\n",
    "        gtab = gradient_table(bvals, bvecs,atol=0.15,b0_threshold=b0_min)\n",
    "\n",
    "        data_undenoise = img_data\n",
    "        if para == None:\n",
    "            para = [3,2.3,3]\n",
    "        else:\n",
    "            para = para\n",
    "        t = time()\n",
    "        sigma = pca_noise_estimate(data_undenoise, gtab, correct_bias=True, smooth=para[0])\n",
    "        # save sigma\n",
    "        save_nifti('sigma_3d.nii', sigma.astype(np.float32), img_affine,hdr=img.header)\n",
    "        print(\"Sigma estimation time\", time() - t)\n",
    "        t = time()\n",
    "        if method == None:\n",
    "            p_method = 'svd'\n",
    "        else:\n",
    "            p_method = method\n",
    "        denoised_arr = localpca(data_undenoise, sigma, tau_factor=para[1], patch_radius=para[2],pca_method=p_method)\n",
    "        print(\"Time taken for local PCA\", -t + time())\n",
    "        # save results\n",
    "        save_nifti(data_out+'.nii', denoised_arr.astype(np.int16), img_affine,hdr=img.header)\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_cal(brain_path,dwi_name,b_name,mask,b0_min,threshold_rgb):\n",
    "    '''\n",
    "    Study_folder\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    from dipy.data import get_fnames\n",
    "    from dipy.io.gradients import read_bvals_bvecs\n",
    "    from dipy.io.image import load_nifti, save_nifti\n",
    "    from dipy.segment.mask import median_otsu\n",
    "    from dipy.reconst.dti import TensorModel\n",
    "    from time import time\n",
    "    from dipy.denoise.localpca import localpca\n",
    "    from dipy.denoise.pca_noise_estimate import pca_noise_estimate\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    import nipype.interfaces.fsl as fsl #topup\n",
    "    from nipype.interfaces.fsl import TOPUP\n",
    "    from nipype.interfaces.fsl import ApplyTOPUP\n",
    "    from nipype.interfaces.fsl import Eddy\n",
    "    from nipype.interfaces.fsl import ExtractROI\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    from nibabel.nifti1 import Nifti1Header\n",
    "    from tqdm.notebook import tqdm\n",
    "    from dipy.io.image import load_nifti, save_nifti\n",
    "    from dipy.io import read_bvals_bvecs\n",
    "    import pandas as pd\n",
    "    from dipy.segment.mask import segment_from_cfa\n",
    "    from dipy.segment.mask import bounding_box\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.ndimage.morphology import binary_dilation\n",
    "    \n",
    "    for Study_folder in tqdm(brain_path):\n",
    "        os.chdir(Study_folder)\n",
    "        data_prefix = dwi_name\n",
    "        dwi_file = os.path.join(Study_folder,data_prefix+'.nii') # 4D diffusion data file name\n",
    "        data,affine,img = load_nifti(dwi_file,return_img=True)\n",
    "        mask_file = os.path.join(Study_folder,mask+'.nii') # 4D diffusion data file name\n",
    "        mask,mask_affine,mask_img = load_nifti(mask_file,return_img=True)\n",
    "        bval = os.path.join(Study_folder,b_name+'.bval') # bval file name\n",
    "        bvec = os.path.join(Study_folder,b_name+'.bvec') # bvec file name\n",
    "        #------------\n",
    "        bvals, bvecs = read_bvals_bvecs(bval,bvec)\n",
    "        gtab = gradient_table(bvals, bvecs,atol=0.05,b0_threshold=b0_min)\n",
    "        # generate rgb maps\n",
    "        tenmodel = TensorModel(gtab)\n",
    "        tensorfit = tenmodel.fit(data, mask=mask)\n",
    "        # find the red region (CC) after generating rgb maps\n",
    "        print('Computing worst-case/best-case SNR using the corpus callosum...')\n",
    "        if threshold_rgb == None:\n",
    "            threshold = (0.3, 1, 0, 0.26, 0, 0.26)\n",
    "        else:\n",
    "            threshold = threshold_rgb\n",
    "        CC_box = np.zeros_like(data[..., 0])\n",
    "        mins, maxs = bounding_box(mask)\n",
    "        mins = np.array(mins)\n",
    "        maxs = np.array(maxs)\n",
    "        print(mins,maxs)\n",
    "        diff = (maxs - mins) // 4\n",
    "        bounds_min = mins + diff\n",
    "        bounds_max = maxs - diff\n",
    "        # this is to find the brain tissue bounds\n",
    "        CC_box[bounds_min[0]:bounds_max[0],\n",
    "            bounds_min[1]:bounds_max[1],\n",
    "            bounds_min[2]:bounds_max[2]] = 1\n",
    "\n",
    "        mask_cc_part, cfa = segment_from_cfa(tensorfit, CC_box, threshold,\n",
    "                                            return_cfa=True)\n",
    "        zooms_old = img.header.get_zooms()[:4]\n",
    "        img_new = nib.Nifti1Image(cfa.astype(np.uint8), np.eye(4))\n",
    "        img_new.header.set_zooms(zooms_old[0:4])\n",
    "        save_nifti('cfa_CC_part.nii', (cfa*255).astype(np.uint8), affine,hdr=img_new.header)\n",
    "        img_new = nib.Nifti1Image(mask_cc_part.astype(np.uint8), np.eye(4))\n",
    "        img_new.header.set_zooms(zooms_old[0:3])\n",
    "        save_nifti('mask_CC_part.nii', mask_cc_part.astype(np.uint8), affine,hdr=img_new.header)\n",
    "        # plot cc region found\n",
    "        region = int(mask.shape[0]//2)\n",
    "        fig = plt.figure('Corpus callosum segmentation')\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Corpus callosum (CC)\")\n",
    "        plt.axis('off')\n",
    "        red = cfa[..., 0]\n",
    "        plt.imshow(np.rot90(red[region,:,:]))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"CC mask used for SNR computation\")\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.rot90(mask_cc_part[region, ...]))\n",
    "        fig.savefig(\"CC_segmentation.png\", bbox_inches='tight',dpi=400)\n",
    "        # \n",
    "        mean_signal = np.mean(data[mask_cc_part], axis=0)\n",
    "        mask_noise = binary_dilation(mask, iterations=10)\n",
    "        mask_noise[..., :mask_noise.shape[-1]//2] = 1\n",
    "        mask_noise = ~mask_noise\n",
    "        #\n",
    "        save_nifti('mask_noise.nii', mask_noise.astype(np.uint8), affine,hdr=img_new.header)\n",
    "        noise_std = np.std(data[mask_noise, :])\n",
    "        print('Noise standard deviation sigma= ', noise_std)\n",
    "\n",
    "        # Exclude null bvecs from the search\n",
    "        idx = np.sum(gtab.bvecs, axis=-1) == 0\n",
    "        gtab.bvecs[idx] = np.inf\n",
    "        axis_X = np.argmin(np.sum((gtab.bvecs-np.array([1, 0, 0]))**2, axis=-1))\n",
    "        axis_Y = np.argmin(np.sum((gtab.bvecs-np.array([0, 1, 0]))**2, axis=-1))\n",
    "        axis_Z = np.argmin(np.sum((gtab.bvecs-np.array([0, 0, 1]))**2, axis=-1))\n",
    "\n",
    "        snr_save = np.zeros(5)# first four are snrs, the last is standard deviation\n",
    "        snr_save[4] = noise_std\n",
    "        i_snr = -1\n",
    "        for direction in [0, axis_X, axis_Y, axis_Z]:\n",
    "            i_snr = i_snr +1\n",
    "            SNR = mean_signal[direction]/noise_std\n",
    "            if direction == 0:\n",
    "                print(\"SNR for the b=0 image is :\", SNR)\n",
    "            else:\n",
    "                print(\"SNR for direction\", direction, \" \",\n",
    "                    gtab.bvecs[direction], \"is :\", SNR)\n",
    "            snr_save[i_snr] = SNR\n",
    "        np.savetxt('snr_'+data_prefix,snr_save,fmt='%1.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_display(brain_path,snr1,snr2,label1,label2,title):\n",
    "    '''\n",
    "    '''\n",
    "    import matplotlib.pylab as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    for Study_folder in tqdm(brain_path):\n",
    "        os.chdir(Study_folder)\n",
    "        if snr2 != None:\n",
    "            snr_0 = np.loadtxt(os.path.join(Study_folder,snr1))\n",
    "            snr_d = np.loadtxt(os.path.join(Study_folder,snr2))\n",
    "            plt.figure()\n",
    "            plt.subplot()\n",
    "            plt.bar(np.arange(len(snr_d)),height=snr_0,width=0.4,label=label1)\n",
    "            for i_text in np.arange(len(snr_0)):\n",
    "                plt.text(np.arange(len(snr_0))[i_text]-0.2,snr_0[i_text],snr_0[i_text])\n",
    "\n",
    "            plt.bar(np.arange(len(snr_d))+0.4,height=snr_d,width=0.4,label=label2)\n",
    "            for i_text in np.arange(len(snr_d)):\n",
    "                plt.text(np.arange(len(snr_d))[i_text]+0.2,snr_d[i_text],snr_d[i_text])\n",
    "\n",
    "            plt.xticks(np.arange(len(snr_d))+0.2,['b0','x','y','z','std(noise)'])\n",
    "            plt.ylabel('SNR (or values)')\n",
    "            plt.legend()\n",
    "            plt.savefig(title+'.png',dpi=200,facecolor='w', edgecolor='w',bbox_inches=None,pad_inchies=None,transparent=False)\n",
    "            plt.show()\n",
    "        else:\n",
    "            snr_0 = np.loadtxt(snr1)\n",
    "            plt.figure()\n",
    "            plt.subplot()\n",
    "            plt.bar(np.arange(len(snr_0)),height=snr_0,width=0.4,label=label1)\n",
    "            for i_text in np.arange(len(snr_0)):\n",
    "                plt.text(np.arange(len(snr_0))[i_text]-0.2,snr_0[i_text],snr_0[i_text])\n",
    "            plt.xticks(np.arange(len(snr_0)),['b0','x','y','z','std(noise)'])\n",
    "            plt.ylabel('SNR (or values)')\n",
    "            plt.legend()\n",
    "            plt.savefig(title+'.png',dpi=200,facecolor='w', edgecolor='w',bbox_inches=None,pad_inchies=None,transparent=False)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion1 denoising\n",
    "brain_path = brain_path = ['/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Diffusion2/']\n",
    "dwi_denoise(brain_path,dwi_name='dwi_mb0',b_name='dwi_mb0',\n",
    "            b0_min=5,para=None,method=None,data_out='dwi_d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6a818820a2d4b94df252b23f7d311b5b1a3798c769b2a454cee3c1911e726f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
