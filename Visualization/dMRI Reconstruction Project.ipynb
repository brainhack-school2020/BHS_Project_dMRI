{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dMRI Data Reconstruction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will reconstruct MRI imgaes from raw data by using Python.This includes: 1. Data processing; 2. DTI reconstruction and 3. DKI reocnstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is quit important for dMRI reconstruction. Different data preprocessing may lead to different reconstruction image qualities, which will make the comparation of different reconstruct methods unreliable. Thus, here we first preprocessing MRI by following same steps: denosing, topup (susceptibility-induced distortion correction) and eddy current-induced distortion and motion correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Import python libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #TO control directories\n",
    "import nibabel as nib # read and save medical images\n",
    "\n",
    "import numpy as np\n",
    "from dipy.denoise.localpca import mppca #denoising\n",
    "import nipype.interfaces.fsl as fsl #topup\n",
    "from nipype.interfaces.fsl import TOPUP\n",
    "from nipype.interfaces.fsl import ApplyTOPUP\n",
    "from nipype.interfaces.fsl import Eddy\n",
    "from nipype.testing import anatfile\n",
    "\n",
    "import timeit #compute time, useage: timeit.timeit()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data path and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/erjun/githubEZ/dMRI_BHS/dMRI_data/dwi\"\n",
    "ap_file = 'sub-032216_ses-001_dir-AP_run-1_dwi.nii.gz' # dMRI data\n",
    "pa_file = 'sub-032216_ses-001_dir-PA_run-1_dwi.nii.gz' \n",
    "bvals_file = 'sub-032216_ses-001_dir-AP_run-1_dwi.bval' # bval file\n",
    "bvecs_file = 'sub-032216_ses-001_dir-AP_run-1_dwi.bvec' # bvec file\n",
    "denoised_file = 'sub-032216_ses-001_dir-AP_run-1_dwi_denoised.nii.gz' # output file after denoising\n",
    "\n",
    "cwdir = os.getcwd()\n",
    "os.chdir(data_path) #directory setting\n",
    "# Load images\n",
    "img = nib.load(os.path.join(data_path,ap_file)) # path.join connects data path given by\n",
    "data = img.get_data()# I,age data array but without position information; need to be combine with image.affine (data position info)\n",
    "# Use dipy to denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type (NII.GZ)\n",
    "\n",
    "- NII (NifTI, format by Neuroimaging Informatics Technology Initiative ) file is commonly used format for multi-dimensional (can be up to 7-dimensional) neuroimaging data. Fisrt four dimension: spatial dimensions and time. \n",
    "\n",
    "- GZ means gzip-compressed NII files.\n",
    "* nib.nifil.Nifti1Image: three parts included in, namely, image data array, an affine array and image metadata.\n",
    "* image metadata: machine info., voxel size and slices\n",
    "\n",
    "Thus, in order to know the exact position of each voxel, we have to combine image data array and affine array. For more information, please check [fMRI Processing based on python](https://ff120.github.io/2016/06/12/%E8%AE%A4%E7%9F%A5%E7%A5%9E%E7%BB%8F%E7%A7%91%E5%AD%A6%E4%B8%93%E9%A2%98/%E4%BD%BF%E7%94%A8Python%E5%A4%84%E7%90%86fMRI%E6%95%B0%E6%8D%AE/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Denoising__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use [Marcenko-Pastur PCA algorithm](https://dipy.org/documentation/1.0.0./examples_built/denoise_mppca/) to denoise images. This algorithm has been shown to provide an optimal compromise between noise suppression and loss of anatomical information for different techniques such as DTI.\n",
    "\n",
    "During the denoising, mppca use a 3D sliding window (decised by denoising radius, pathc_radius) to denoise. Basicaly, this 3D sliding window voxles should be larger than DTI volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = mppca(data, patch_radius=4) # If volume is about 67, pathc_radius can be set to 2\n",
    "# Save data \n",
    "nib.save(nib.Nifti1Image(data, img.affine), os.path.join(data_path,denoised_file))\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default output type and test ExtractROI tool for Define b_0 image extraction function\n",
    "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "# This is used to test fsl.ExtractROI, if you see bar.nii.gz file in the data_path, it works well.\n",
    "fslroi = fsl.ExtractROI(in_file=anatfile, roi_file='bar.nii.gz', t_min=0,t_size=1)\n",
    "fslroi.cmdline == 'fslroi %s bar.nii.gz 0 1' % anatfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define b_0 image extraction function\n",
    "\n",
    "def Extract_b0_Image(input_Image, output_Image):\n",
    "    \"To run this, please first make sure you install fsl and can run it\"\n",
    "    \"One method is that run fsl and thi pre-processing code in the same terminal\"\n",
    "    fslroi = fsl.ExtractROI(in_file=input_Image,roi_file=output_Image,t_min=0, t_size=1)\n",
    "    fslroi.run()\n",
    "    \n",
    "# Test\n",
    "#extract_b0(ap_file, 'bar.nii.gz')\n",
    "#fslroi.cmdline == 'fslroi %s bar.nii.gz 0 1' % ap_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract b0 images\n",
    "Extract_b0_Image(ap_file, 'epi_b0.nii.gz')\n",
    "Extract_b0_Image(pa_file, 'epi_rev_b0.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nib_rd_img(path):\n",
    "    image_data = nib.load(path).get_data()\n",
    "    return image_data\n",
    "def nib_show_img(img0):\n",
    "    img00=img0[:,:,30]\n",
    "    zmax0=img00.max()\n",
    "    fig=px.imshow(img0[:,:,30],color_continuous_scale=\"Viridis\",zmin=0,zmax=10000,x=None, y=None,labels={},template=\"plotly_white\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data22 = nib_rd_img('epi_b0.nii.gz')\n",
    "nib_show_img(data22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fslmerge to concatenate images\n",
    "merger = fsl.Merge()\n",
    "merger.inputs.in_files = ['epi_b0.nii.gz','epi_rev_b0.nii.gz']\n",
    "merger.inputs.dimension = 't'\n",
    "merger.inputs.output_type = 'NIFTI_GZ'\n",
    "#merger = fsl.Merge(in_files=['epi_b0.nii.gz','epi_rev_b0.nii.gz'],dimension = 't',output_type='NIFTI_GZ')\n",
    "merger.run()\n",
    "\n",
    "file = open('topup_encoding.txt','w')\n",
    "file.write('0 1 0 0.05\\n0 -1 0 0.05')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topup = TOPUP()\n",
    "topup.inputs.in_file = 'epi_b0_merged.nii.gz'\n",
    "topup.inputs.encoding_file = \"topup_encoding.txt\"\n",
    "topup.inputs.output_type = 'NIFTI_GZ'\n",
    "topup.cmdline\n",
    "topup.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------\n",
    "#            FSL ApplyTOPUP \n",
    "#------------------------------------------------\n",
    "applytopup = ApplyTOPUP()\n",
    "applytopup.inputs.in_files = ['epi_b0.nii.gz', 'epi_rev_b0.nii.gz']\n",
    "applytopup.inputs.encoding_file = \"topup_encoding.txt\"\n",
    "applytopup.inputs.in_topup_fieldcoef = \"epi_b0_merged_base_fieldcoef.nii.gz\"\n",
    "applytopup.inputs.in_topup_movpar = \"epi_b0_merged_base_movpar.txt\"\n",
    "applytopup.inputs.output_type = \"NIFTI_GZ\"\n",
    "applytopup.cmdline\n",
    "applytopup.run()        \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btr = fsl.BET(in_file= 'epi_b0.nii.gz',#'epi_b0_corrected.nii.gz',\n",
    "              frac=0.2, out_file='brain.nii.gz', mask=True)\n",
    "btr.run()\n",
    "\n",
    "# total nuber of volumes in dwi data\n",
    "img = nib.load(denoised_file).get_data()\n",
    "nvolumes = img.shape[-1]\n",
    "\n",
    "file = open('index.txt','w')\n",
    "for i in range(0, nvolumes):\n",
    "    file.write('1 ')\n",
    "file.close()\n",
    "\n",
    "eddy = Eddy()\n",
    "eddy.inputs.in_file = denoised_file\n",
    "eddy.inputs.in_mask  = 'brain_mask.nii.gz'\n",
    "eddy.inputs.in_index = 'index.txt'\n",
    "eddy.inputs.in_acqp  = 'topup_encoding.txt'\n",
    "eddy.in_topup_fieldcoef = \"epi_b0_merged_base_fieldcoef.nii.gz\"\n",
    "eddy.inputs.in_bvec  = bvecs_file\n",
    "eddy.inputs.in_bval  = bvals_file\n",
    "eddy.inputs.use_cuda = False\n",
    "eddy.inputs.is_shelled=True\n",
    "eddy.cmdline\n",
    "eddy.run() \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTI Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from skimage import io #用于读取保存或显示图片或者视频\n",
    "import time\n",
    "\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.reconst.dti import fractional_anisotropy\n",
    "from dipy.reconst.dti import color_fa\n",
    "import dipy.reconst.dki as dki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new data path for DTI reconstruction\n",
    "#data_path = \"/home/erjun/githubEZ/dHCP/sub-CC00060XX03/ses-12501/dwi\"\n",
    "#dwi_file = 'sub-CC00060XX03_ses-12501_desc-preproc_dwi.nii.gz'\n",
    "brainmask_file = 'brain_mask.nii.gz'\n",
    "#bval = 'sub-CC00060XX03_ses-12501_desc-preproc_dwi.bval'\n",
    "#bvec = 'sub-CC00060XX03_ses-12501_desc-preproc_dwi.bvec'\n",
    "#os.chdir(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data files\n",
    "img1 = nib.load(os.path.join(data_path,ap_file))\n",
    "data = img1.get_data()\n",
    "\n",
    "img2 = nib.load(os.path.join(data_path,brainmask_file))\n",
    "brainmask = img2.get_data()\n",
    "\n",
    "bvals, bvecs = read_bvals_bvecs(os.path.join(bvals_file),\n",
    "                                os.path.join(data_path,bvecs_file))\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTI model\n",
    "ten_model = TensorModel(gtab)\n",
    "ten_fit = ten_model.fit(data, brainmask)\n",
    "        \n",
    "# Save DTI parametric maps\n",
    "if not os.path.exists(data_path+'/DTI/'):\n",
    "    os.mkdir(data_path+'/DTI')\n",
    "output_path = data_path+'/DTI/'\n",
    "        \n",
    "DTI_FA = ten_fit.fa\n",
    "DTI_AD = ten_fit.ad\n",
    "DTI_RD = ten_fit.rd\n",
    "DTI_MD = ten_fit.md\n",
    "        \n",
    "nib.save(nib.Nifti1Image(DTI_FA, img1.affine), os.path.join(output_path,'FA.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DTI_MD, img1.affine), os.path.join(output_path,'MD.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DTI_RD, img1.affine), os.path.join(output_path,'RD.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DTI_AD, img1.affine), os.path.join(output_path,'AD.nii.gz'))\n",
    "    \n",
    "#Save FA RGB map\n",
    "fa = fractional_anisotropy(ten_fit.evals)\n",
    "cfa = color_fa(fa, ten_fit.evecs)\n",
    "DTI_FA = np.clip(fa, 0, 1)\n",
    "DTI_RGB = color_fa(fa, ten_fit.evecs)\n",
    "\n",
    "nib.save(nib.Nifti1Image(np.array(255 * cfa, 'uint8'), img1.affine), os.path.join(output_path,'FA_RGB.nii.gz'))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DKI MODEL\n",
    "dkimodel = dki.DiffusionKurtosisModel(gtab)\n",
    "dkifit = dkimodel.fit(data, brainmask)\n",
    "        \n",
    "# Save DKI parametric maps\n",
    "if not os.path.exists(data_path+'/DKI/'):\n",
    "    os.mkdir(data_path+'/DKI')\n",
    "data_path_saveImage = data_path+'/DKI/'\n",
    "        \n",
    "DKI_FA = dkifit.fa\n",
    "DKI_MD = dkifit.md\n",
    "DKI_RD = dkifit.rd\n",
    "DKI_AD = dkifit.ad\n",
    "\n",
    "DKI_MK = dkifit.mk(0, 3)\n",
    "DKI_AK = dkifit.ak(0, 3)\n",
    "DKI_RK = dkifit.rk(0, 3)\n",
    "        \n",
    "nib.save(nib.Nifti1Image(DKI_FA, img1.affine), os.path.join(data_path_saveImage,'dki_FA.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DKI_MD, img1.affine), os.path.join(data_path_saveImage,'dki_MD.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DKI_RD, img1.affine), os.path.join(data_path_saveImage,'dki_RD.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DKI_AD, img1.affine), os.path.join(data_path_saveImage,'dki_AD.nii.gz'))\n",
    "        \n",
    "nib.save(nib.Nifti1Image(DKI_AK, img1.affine), os.path.join(data_path_saveImage,'AK.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DKI_RK, img1.affine), os.path.join(data_path_saveImage,'RK.nii.gz'))\n",
    "nib.save(nib.Nifti1Image(DKI_MK, img1.affine), os.path.join(data_path_saveImage,'MK.nii.gz'))\n",
    "        \n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I first show the basic images generate during preprocessing and final image reconstruction process. Then I will go the data visualization part. And before that, to create images more eassily, I will definie several image showing function first.\n",
    "\n",
    "All the images are generated from this project and base on the data preprocessing and iamge reconstruction part.\n",
    "\n",
    "Let's go to check what basic images we aready have!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTI Images\n",
    "# set plot background\n",
    "#plt.style.use('seaborn-dark')\n",
    "plt.style.context('dark_background')\n",
    "# plot paramter maps          \n",
    "fig, [ax0, ax2, ax3, ax4] = plt.subplots(1,4,figsize=(10,8),subplot_kw={'xticks': [], 'yticks': []})\n",
    "ax0.imshow(DTI_RGB[:,:,30,:]); ax0.set_title('Color coded FA',fontweight='bold',size=10)\n",
    "#ax1.imshow(DTI_FA[:,30,:]); ax1.set_title('Fractional anisotropy',fontweight='bold',size=10)\n",
    "ax2.imshow(DTI_MD[:,:,30]); ax2.set_title('Mean diffusivity',fontweight='bold',size=10)\n",
    "ax3.imshow(DTI_RD[:,:,30]); ax3.set_title('Radial diffusivity',fontweight='bold',size=10)\n",
    "ax4.imshow(DTI_AD[:,:,30]); ax4.set_title('Axial diffusivity',fontweight='bold',size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DKI images         \n",
    "fig, ([ax0, ax1, ax2],[ax3, ax4, ax5]) = plt.subplots(2,3,figsize=(10,8),subplot_kw={'xticks': [], 'yticks': []})\n",
    "ax0.imshow(DKI_AD[:,:,30]); ax0.set_title('Axial diffusivity',fontweight='bold',size=10)\n",
    "ax1.imshow(DKI_RD[:,:,30]); ax1.set_title('Radial diffusivity',fontweight='bold',size=10)\n",
    "ax2.imshow(DKI_MD[:,:,30]); ax2.set_title('Mean diffusivity',fontweight='bold',size=10)\n",
    "ax3.imshow(DKI_AK[:,:,30]); ax3.set_title('Axial kurtosis',fontweight='bold',size=10)\n",
    "ax4.imshow(DKI_RK[:,:,30]); ax4.set_title('Radial kurtosis',fontweight='bold',size=10)\n",
    "ax5.imshow(DKI_MK[:,:,30]); ax5.set_title('Mean kurtosis',fontweight='bold',size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to show images definition\n",
    "#------------To read and show images from nii.gz file-------------------------------\n",
    "def nib_read_img(path):\n",
    "    image_data = nib.load(path).get_data()\n",
    "    return image_data\n",
    "def nib_show_img(img0,slices,intenseScale):\n",
    "    img00=img0[:,:,slices]\n",
    "    zmax0=img00.max()\n",
    "    fig=px.imshow(img0[:,:,slices],color_continuous_scale=\"Viridis\",zmin=0,zmax=zmax0*intenseScale/100,x=None, y=None,labels={},template=\"plotly_white\")\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.show()\n",
    "#------------------To make functions above shorter-----------------------------------\n",
    "def nib_rdshow_img(Images,Slices,IntenseScale,TitleImg):\n",
    "    'Images: data path; Slices: which slice you want to see; IntenseScale: to percentage of the highest color strength'\n",
    "    \"TitleImg:image title, for example:'a test title'\"\n",
    "    warnings.filterwarnings('ignore')\n",
    "    image_data = nib.load(Images).get_data()\n",
    "    img00=image_data[:,:,Slices]\n",
    "    zmax0=img00.max()\n",
    "    fig=px.imshow(image_data[:,:,Slices],color_continuous_scale=\"Viridis\",\\\n",
    "                  zmin=0,zmax=zmax0*IntenseScale/100,\\\n",
    "                  labels={},template=\"plotly_white\")\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_layout(title=TitleImg)\n",
    "    fig.show()\n",
    "#--------------------Define a function to show volume slices images--------------------\n",
    "# Visualization of MRI volume slices\n",
    "def vol_plot(x):\n",
    "    \"to create 3D  MRI figure with slider\"\n",
    "    vol = x\n",
    "    colormax = vol.max()#获取最大array中的最大值，最后代表cmax\n",
    "    volume = vol.T\n",
    "    len(volume)\n",
    "    r, c = volume[math.floor(len(volume)/2)].shape\n",
    "    # Define frames\n",
    "    import plotly.graph_objects as go\n",
    "    nb_frames = len(volume)-1\n",
    "    fig = go.Figure(frames=[go.Frame(\n",
    "        data=go.Surface(\n",
    "        z=(len(volume)-1 - k ) * np.ones((r, c)),\n",
    "        surfacecolor=volume[len(volume)-1 - k],\n",
    "        cmin=0, cmax=colormax\n",
    "        ),\n",
    "        name=str(k) # name the frame for the animation to behave properly\n",
    "        )\n",
    "        for k in range(nb_frames)])\n",
    "\n",
    "    # Add data to be displayed before animation starts\n",
    "    fig.add_trace(go.Surface(\n",
    "        z=(len(volume)-1) * np.ones((r, c)),\n",
    "        surfacecolor=volume[len(volume)-1],#np.flipud(volume[30]),\n",
    "        colorscale='gray',\n",
    "        cmin=0, cmax=colormax,\n",
    "        colorbar=dict(thickness=20, ticklen=4)\n",
    "        ))\n",
    "\n",
    "    def frame_args(duration):\n",
    "        return {\n",
    "                \"frame\": {\"duration\": 500},# Duration can be used to change animate speed\n",
    "                \"mode\": \"immediate\",\n",
    "                \"fromcurrent\": True,\n",
    "                \"transition\": {\"duration\": 500, \"easing\": \"linear\"},\n",
    "            }\n",
    "\n",
    "    sliders = [\n",
    "                {\n",
    "                    \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                    \"len\": 0.9,\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0,\n",
    "                    \"steps\": [\n",
    "                        {\n",
    "                            \"args\": [[f.name], frame_args(0)],\n",
    "                            \"label\": str(k),\n",
    "                            \"method\": \"animate\",\n",
    "                        }\n",
    "                        for k, f in enumerate(fig.frames)\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "             title='Slices in volumetric data',\n",
    "             width=600,\n",
    "             height=600,\n",
    "             scene=dict(\n",
    "                        zaxis=dict(range=[-1, len(volume)-1], autorange=False),\n",
    "                        aspectratio=dict(x=1, y=1, z=1),\n",
    "                        ),\n",
    "             updatemenus = [\n",
    "                {\n",
    "                    \"buttons\": [\n",
    "                        {\n",
    "                            \"args\": [None, frame_args(50)],\n",
    "                            \"label\": \"&#9654;\", # play symbol\n",
    "                            \"method\": \"animate\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"args\": [[None], frame_args(0)],\n",
    "                            \"label\": \"&#9724;\", # pause symbol\n",
    "                            \"method\": \"animate\",\n",
    "                        },\n",
    "                    ],\n",
    "                    \"direction\": \"left\",\n",
    "                    \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                    \"type\": \"buttons\",\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0,\n",
    "                }\n",
    "             ],\n",
    "             sliders=sliders\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "#---------------------------Update function above------------------------------------\n",
    "def interact_vol_plot(x,IntenseScale):\n",
    "    \"to create 3D  MRI figure with slider\"\n",
    "    vol = x\n",
    "    colormax = IntenseScale*vol.max()#获取最大array中的最大值，最后代表cmax\n",
    "    volume = vol.T\n",
    "    len(volume)\n",
    "    r, c = volume[math.floor(len(volume)/2)].shape\n",
    "    # Define frames\n",
    "    import plotly.graph_objects as go\n",
    "    nb_frames = len(volume)-1\n",
    "    fig = go.Figure(frames=[go.Frame(\n",
    "        data=go.Surface(\n",
    "        z=(len(volume)-1 - k ) * np.ones((r, c)),\n",
    "        surfacecolor=volume[len(volume)-1 - k],\n",
    "        cmin=0, cmax=colormax\n",
    "        ),\n",
    "        name=str(k) # name the frame for the animation to behave properly\n",
    "        )\n",
    "        for k in range(nb_frames)])\n",
    "\n",
    "    # Add data to be displayed before animation starts\n",
    "    fig.add_trace(go.Surface(\n",
    "        z=(len(volume)-1) * np.ones((r, c)),\n",
    "        surfacecolor=volume[len(volume)-1],#np.flipud(volume[30]),\n",
    "        colorscale='gray',\n",
    "        cmin=0, cmax=colormax,\n",
    "        colorbar=dict(thickness=20, ticklen=4)\n",
    "        ))\n",
    "    def frame_args(duration):\n",
    "        return {\n",
    "                \"frame\": {\"duration\": 500},# Duration can be used to change animate speed\n",
    "                \"mode\": \"immediate\",\n",
    "                \"fromcurrent\": True,\n",
    "                \"transition\": {\"duration\": 500, \"easing\": \"linear\"},\n",
    "            }\n",
    "\n",
    "    sliders = [\n",
    "                {\n",
    "                    \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                    \"len\": 0.9,\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0,\n",
    "                    \"steps\": [\n",
    "                        {\n",
    "                            \"args\": [[f.name], frame_args(0)],\n",
    "                            \"label\": str(k),\n",
    "                            \"method\": \"animate\",\n",
    "                        }\n",
    "                        for k, f in enumerate(fig.frames)\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "             title='Volume Slices Image',\n",
    "             width=600,\n",
    "             height=600,\n",
    "             scene=dict(\n",
    "                        zaxis=dict(range=[-1, len(volume)-1], autorange=False),\n",
    "                        aspectratio=dict(x=1, y=1, z=1),\n",
    "                        ),\n",
    "             updatemenus = [\n",
    "                {\n",
    "                    \"buttons\": [\n",
    "                        {\n",
    "                            \"args\": [None, frame_args(50)],\n",
    "                            \"label\": \"&#9654;\", # play symbol\n",
    "                            \"method\": \"animate\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"args\": [[None], frame_args(0)],\n",
    "                            \"label\": \"&#9724;\", # pause symbol\n",
    "                            \"method\": \"animate\",\n",
    "                        },\n",
    "                    ],\n",
    "                    \"direction\": \"left\",\n",
    "                    \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                    \"type\": \"buttons\",\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0,\n",
    "                }\n",
    "             ],\n",
    "             sliders=sliders\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D volume slice image\n",
    "\n",
    "This images will quickly check the general apperance of you images during the slice-by-slice animation. One can also rotate it and zoom in to see clearly.\n",
    "\n",
    "Here, as an example, I just show FA map generated from DTI model. Once can change it to other maps, such as DTI_MD or DKI_FA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vol_plot(DTI_FA[:,:,:]) # or can use interact_vol_plot(DTI_MD,90) to show images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization (Preprocessing part)\n",
    "\n",
    "I am curious about what changed of the iamges during our data preprocessing. This interactive images can be used to reach this purpose.\n",
    "\n",
    "One can control Slices to check different slice changes among them. You can control the level of high color scale to get higher image contrast. You can put cursor on images to get the exact color value if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nib_rdshow_play(Slices,IntenseScale,NoX):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    if(NoX==0):\n",
    "        Image='epi_b0.nii.gz'\n",
    "        TitleImg='Preprocess: bo image after extraction '\n",
    "    elif(NoX==1):\n",
    "        Image='epi_b0_merged.nii.gz'\n",
    "        TitleImg='Preprocess: merge'\n",
    "    elif(NoX==2):\n",
    "        Image='epi_b0_merged_corrected.nii.gz'\n",
    "        TitleImg='Preprocess: merge corrected'\n",
    "    elif(NoX==3):\n",
    "        Image='eddy_corrected.nii.gz'\n",
    "        TitleImg='Preprocess: EDDY corrected'\n",
    "    else:\n",
    "        Image='brain.nii.gz'\n",
    "        TitleImg='Preprocess: final'\n",
    "    image_data = nib.load(Image).get_data()\n",
    "    img00=image_data[:,:,Slices]\n",
    "    zmax0=img00.max()\n",
    "    fig=px.imshow(image_data[:,:,Slices],color_continuous_scale=\"Viridis\",\\\n",
    "                  zmin=0,zmax=zmax0*IntenseScale/100,\\\n",
    "                  labels={},template=\"plotly_white\")\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_layout(title=TitleImg)\n",
    "    fig.show()\n",
    "interactive(nib_rdshow_play,Slices=widgets.IntSlider(min=0,max=43,step=1,value=22),\\\n",
    "         IntenseScale=widgets.IntSlider(min=0,max=100,step=1,value=90),\\\n",
    "           NoX = widgets.Play(value=0,min=0,max=4,step=1,interval=1000,description=\"Press play\",\\\n",
    "                                   disabled=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization (Reconstruction part)\n",
    "\n",
    "This part is used to compare images generated from DTI and DKI models. The founction is almost the same as virsualizaiotn above. But to make us better choose iamges, we use dropdown bar to replace slider animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image data file\n",
    "Images= dict()\n",
    "Images['DTI_FA_RGB']=data_path+'/DTI/FA_RGB.nii.gz'\n",
    "Images['DTI_AD']=data_path+'/DTI/AD.nii.gz'\n",
    "Images['DTI_FA']=data_path+'/DTI/FA.nii.gz'\n",
    "Images['DTI_MD']=data_path+'/DTI/MD.nii.gz'\n",
    "Images['DTI_RD']=data_path+'/DTI/RD.nii.gz'\n",
    "\n",
    "Images['DKI_AD']=data_path+'/DKI/dki_AD.nii.gz'\n",
    "Images['DKI_FA']=data_path+'/DKI/dki_FA.nii.gz'\n",
    "Images['DKI_MD']=data_path+'/DKI/dki_MD.nii.gz'\n",
    "Images['DKI_RD']=data_path+'/DKI/dki_RD.nii.gz'\n",
    "Images['DKI_AK']=data_path+'/DKI/AK.nii.gz'\n",
    "Images['DKI_MK']=data_path+'/DKI/MK.nii.gz'\n",
    "Images['DKI_RK']=data_path+'/DKI/RK.nii.gz'\n",
    "\n",
    "\n",
    "\n",
    "interactive(nib_rdshow_img,Images=Images,Slices=widgets.IntSlider(min=0,max=43,step=1,value=22),\\\n",
    "         IntenseScale=widgets.IntSlider(min=0,max=100,step=1,value=90),\\\n",
    "           TitleImg='Reconstructed Images of Different Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
