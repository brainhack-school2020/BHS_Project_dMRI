{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_to_b0(dwi_path,dwi_name,b_prefix,output_name,b_output_name):\n",
    "    '''\n",
    "    dwi_to_b0(brain_path=brain_path,dwi_name='dwi_topuped',b_prefix='dwi',output_name='dwi_to_b0',b_output_name)\n",
    "    '''\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    import nibabel as nib\n",
    "    from dipy.io.image import load_nifti,save_nifti\n",
    "    from dipy.io import read_bvals_bvecs\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    from dipy.core.gradients import reorient_bvecs\n",
    "    from dipy.align import register_series, center_of_mass,translation,rigid\n",
    "    from dipy.align._public import affine,register_dwi_series,syn_registration,register_dwi_to_template\n",
    "    data_prefix = dwi_name\n",
    "    b_prefix = b_prefix\n",
    "    dwi_file = os.path.join(dwi_path,data_prefix+'.nii') # 4D diffusion data file name\n",
    "    bval = os.path.join(dwi_path,b_prefix+'.bval') # bval file name\n",
    "    bvec = os.path.join(dwi_path,b_prefix+'.bvec') # bvec file name\n",
    "    #------------\n",
    "    bvals, bvecs = read_bvals_bvecs(bval,bvec)\n",
    "    gtab = gradient_table(bvals, bvecs,atol=0.15,b0_threshold=5)\n",
    "    img_data,img_affine,img = load_nifti(dwi_file,return_img=True)\n",
    "    xformed,affines = register_dwi_series(img_data,gtab,affine=img_affine,b0_ref=0,\n",
    "                                            pipeline= [center_of_mass, translation,rigid,affine])#,syn_registration\n",
    "    affines1 = affines.swapaxes(1,2).swapaxes(0,1)[~gtab.b0s_mask]\n",
    "    gtab_new = reorient_bvecs(gtab, affines1, atol=0.15)\n",
    "    np.savetxt(os.path.join(dwi_path,b_output_name+'.bval'),gtab_new.bvals[np.newaxis,:],fmt='%1.5f')\n",
    "    np.savetxt(os.path.join(dwi_path,b_output_name+'.bvec'),gtab_new.bvecs.T,fmt='%1.5f')\n",
    "    # save_nifti_origin(input=xformed.get_data(),output_name=output_name,type_output=np.int16,\n",
    "    #                   zooms=img.header.get_zooms()[:4])\n",
    "    save_nifti(os.path.join(dwi_path,output_name), xformed.get_data(), img_affine,hdr=img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_padding(static,moving_data):\n",
    "    import numpy as np\n",
    "    #padding to make registration working well\n",
    "    pad_by1 = (moving_data.shape[0]-static.shape[0])//2\n",
    "    pad_by2 = (moving_data.shape[1]-static.shape[1])//2\n",
    "    if (pad_by1>=0) and (pad_by2>=0):\n",
    "            moving_data = moving_data[pad_by1:-pad_by1,pad_by2:-pad_by2,:]\n",
    "    elif (pad_by1>=0) and (pad_by2<0):\n",
    "            moving_data = moving_data[pad_by1:-pad_by1,:,:]\n",
    "            moving_data = np.pad(moving_data, [(0, 0), (-pad_by2, -pad_by2), (0, 0)],\n",
    "                            mode='constant', constant_values=0)\n",
    "    elif (pad_by1<0) and (pad_by2>=0):\n",
    "            moving_data = moving_data[:,pad_by2:-pad_by2,:]\n",
    "            moving_data = np.pad(moving_data, [(-pad_by1, -pad_by1),(0, 0), (0, 0)],\n",
    "                            mode='constant', constant_values=0)\n",
    "    elif (pad_by1<0) and (pad_by2<0):\n",
    "            moving_data = np.pad(moving_data, [(-pad_by1, -pad_by1),(-pad_by2, -pad_by2), (0, 0)],\n",
    "                            mode='constant', constant_values=0)\n",
    "    return moving_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_to_t2(dwi_path,t2w_path,transform_file_path,dwi_name,t2w_name,b_input_name,reg_aff_name,sym_name,output_name_base):\n",
    "        '''\n",
    "        dwi_to_t2(brain_path,input_dwi,input_t2,b_input_name,b_output_name,registered_out)\n",
    "        dwi_to_t2_transform(dwi_path,t2w_path,transform_file_path,dwi_name,t2w_name,reg_aff_name,sym_name,output_name_base,transform_dir):\n",
    "        dwi_to_t2(brain_path,input_dwi='dwi_b0_resample.nii',input_t2='T2_resample.nii',b_input_name='',b_output_name='',registered_out='')\n",
    "        '''\n",
    "        import os\n",
    "        import numpy as np\n",
    "        from tqdm import tqdm\n",
    "        import nibabel as nib\n",
    "        from dipy.segment.mask import applymask\n",
    "        from dipy.align.imaffine import (transform_centers_of_mass,\n",
    "                                        AffineMap,\n",
    "                                        MutualInformationMetric)\n",
    "        from dipy.io.image import load_nifti,save_nifti\n",
    "        from dipy.align import affine_registration, register_dwi_to_template,read_mapping,write_mapping,resample\n",
    "        from dipy.io.gradients import read_bvals_bvecs\n",
    "        from dipy.core.gradients import gradient_table,reorient_bvecs\n",
    "        from dipy.align.metrics import CCMetric\n",
    "        from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "        from dipy.viz import regtools\n",
    "        dwi_file = os.path.join(dwi_path,dwi_name)\n",
    "        moving_data,moving_affine,moving_img = load_nifti(dwi_file,return_img=True)\n",
    "        \n",
    "        moving_affine = np.eye(4)\n",
    "        moving_grid2world = moving_affine\n",
    "        \n",
    "        t2_file = os.path.join(t2w_path,t2w_name)\n",
    "        static_data,static_affine_original,static_img = load_nifti(t2_file,return_img=True)\n",
    "        static = static_data\n",
    "        static_affine = np.eye(4)\n",
    "        static_grid2world = static_affine\n",
    "        \n",
    "        #padding to make registration working well\n",
    "        moving_data = data_padding(static,moving_data)\n",
    "        moving = moving_data\n",
    "        #\n",
    "        c_of_mass = transform_centers_of_mass(static, static_grid2world,\n",
    "                                                moving_data, moving_grid2world)\n",
    "        transformed = c_of_mass.transform(moving_data)\n",
    "        print('Image after center of mass transform')\n",
    "        regtools.overlay_slices(static, transformed, None, 2,\n",
    "                                        \"Static\", \"Transformed\", \"0_b0_to_t2w_center_of_mass_registration_test.png\",dpi=500)\n",
    "        #affine parameter\n",
    "        nbins = 32\n",
    "        sampling_prop = None\n",
    "        metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "        level_iters = [10000, 1000, 500]\n",
    "        sigmas = [3.0, 1.0, 0.0]\n",
    "        factors = [4, 2, 1]\n",
    "        pipeline = [\"center_of_mass\",\"translation\", \"rigid\", \"affine\"]#[\"affine\"]#\n",
    "        # affine reg\n",
    "        xformed_img, reg_affine = affine_registration(\n",
    "                                        moving_data,\n",
    "                                        static,\n",
    "                                        moving_affine=moving_affine,\n",
    "                                        static_affine=static_affine,\n",
    "                                        nbins=32,\n",
    "                                        metric='MI',\n",
    "                                        pipeline=pipeline,\n",
    "                                        level_iters=level_iters,\n",
    "                                        sigmas=sigmas,\n",
    "                                        factors=factors,\n",
    "                                        # static_mask=static_mask,\n",
    "                                        # moving_mask=moving_mask,\n",
    "                                        )\n",
    "        regtools.overlay_slices(static, xformed_img, None, 2, 'Static',\n",
    "                                'Warped moving', '1_b0_to_t2w_aff_registration_test.png')\n",
    "        # --------------------------------\n",
    "        # reoriente b table\n",
    "        bval = os.path.join(dwi_path,b_input_name+'.bval') # bval file name\n",
    "        bvec = os.path.join(dwi_path,b_input_name+'.bvec') # bvec file name\n",
    "        bvals, bvecs = read_bvals_bvecs(bval,bvec)\n",
    "        gtab = gradient_table(bvals, bvecs,atol=0.15,b0_threshold=5)\n",
    "        affines0 = np.zeros([len(bvals),4,4])#affines.swapaxes(1,2).swapaxes(0,1)[~gtab.b0s_mask]\n",
    "        for i_affine in np.arange(len(bvals)):\n",
    "            affines0[i_affine,:,:] = reg_affine+1-1\n",
    "        affines1 = affines0[~gtab.b0s_mask]\n",
    "        gtab_new = reorient_bvecs(gtab, affines1, atol=0.15)\n",
    "        np.savetxt(output_name_base+'_reorient.bval',gtab_new.bvals[:,np.newaxis].T,fmt='%1.5f')\n",
    "        np.savetxt(output_name_base+'_reorient.bvec',gtab_new.bvecs.T,fmt='%1.5f')\n",
    "        #----------------------------------\n",
    "\n",
    "        prealign = reg_affine\n",
    "        np.savetxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'.txt'),prealign)#for b0 to t2w\n",
    "\n",
    "        metric = CCMetric(3)\n",
    "        level_iters = [50, 30, 10]#[10,10,5]#[80, 50, 25]#[3,2,1]#\n",
    "        sdr = SymmetricDiffeomorphicRegistration(metric, level_iters)\n",
    "        mapping = sdr.optimize(static, moving, static_affine, moving_affine, prealign)\n",
    "        warped_moving = mapping.transform(moving)\n",
    "        # save and display results\n",
    "        np.savetxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'_mapping.txt'),mapping.prealign)#for b0 to t2w\n",
    "        np.savetxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'_mapping_inv.txt'),mapping.prealign_inv)#for b0 to t2w\n",
    "        write_mapping(mapping,os.path.join(transform_file_path,output_name_base+sym_name))\n",
    "        save_nifti(os.path.join(dwi_path,output_name_base+'_aff_sym_forward_test.nii'),warped_moving,static_affine_original,static_img.header)\n",
    "        regtools.overlay_slices(static, warped_moving, None, 2, 'Static',\n",
    "                                'Warped moving', '2_b0_to_t2w_aff_sym_registration_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_to_t2_transform(dwi_path,t2w_path,transform_file_path,dwi_name,t2w_name,reg_aff_name,sym_name,output_name_base,transform_dir):\n",
    "    '''\n",
    "    transform_dir: eighter 'forward' or 'backward';\n",
    "    '''\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from dipy.io.image import load_nifti,save_nifti\n",
    "    from dipy.align.imaffine import (AffineMap,\n",
    "                                    AffineRegistration)\n",
    "    from dipy.align import read_mapping,resample\n",
    "    import matplotlib.pylab as plt\n",
    "    static_data,static_affine_original,static_img = load_nifti(os.path.join(t2w_path,t2w_name),\n",
    "                                            return_img=True)\n",
    "    static_affine = np.eye(4)\n",
    "    static = np.squeeze(static_data[:,:,:])#*mask\n",
    "    static_grid2world = static_affine\n",
    "\n",
    "    save_nifti(os.path.join(t2w_path,'codomain_test.nii'),static,static_affine,static_img.header)\n",
    "    codomain_img = os.path.join(t2w_path,'codomain_test.nii')\n",
    "\n",
    "    # load moving data\n",
    "    moving_data_original, moving_affine_original, moving_img = load_nifti(os.path.join(dwi_path,dwi_name), return_img=True)\n",
    "    moving_affine = np.eye(4)\n",
    "    moving_data = np.squeeze(moving_data_original)+1-1\n",
    "\n",
    "    # padding\n",
    "    moving_data = data_padding(static,moving_data)\n",
    " \n",
    "    save_nifti(os.path.join(dwi_path,'domain_test.nii'),moving_data,moving_affine,moving_img.header)\n",
    "    domain_img = os.path.join(dwi_path,'domain_test.nii')\n",
    "    #mapping transform\n",
    "    prealign = np.loadtxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'.txt'))\n",
    "    affinemap = AffineMap(prealign, \n",
    "                        domain_grid_shape=moving_data.shape, \n",
    "                        domain_grid2world=moving_affine,\n",
    "                        codomain_grid_shape=static,\n",
    "                        codomain_grid2world=static_affine)\n",
    "    affine_forward = affinemap.transform(moving_data, image_grid2world=moving_affine, sampling_grid_shape=static_data.shape,\n",
    "                        sampling_grid2world=static_affine, resample_only=False)\n",
    "    # affine_img = resample(moving_data, static, moving_affine=moving_affine, static_affine=static_affine,between_affine=prealign)\n",
    "    save_nifti(os.path.join(dwi_path,output_name_base+'_aff_forward.nii'),affine_forward,static_affine_original,static_img.header)\n",
    "    # save_nifti(os.path.join(dwi_path,output_name_base+'_aff_forward_resample.nii'),affine_img.get_fdata(),static_affine_original,static_img.header)\n",
    "    # affine reverse transform\n",
    "    affine_inv = affinemap.transform_inverse(static, image_grid2world=static_affine, sampling_grid_shape=moving_data.shape,\n",
    "                        sampling_grid2world=None, resample_only=False)\n",
    "    data_aff_back = data_padding(moving_data_original,affine_inv)\n",
    "    save_nifti(os.path.join(dwi_path,output_name_base+'_aff_backward.nii'),data_aff_back,moving_affine_original,moving_img.header)\n",
    "    #\n",
    "    mapping_file = os.path.join(transform_file_path,output_name_base+sym_name)\n",
    "    prealign_mapping = np.loadtxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'_mapping.txt'))\n",
    "    mapping = read_mapping(mapping_file,domain_img,codomain_img,prealign_mapping)#prealign\n",
    "    x_transformed = mapping.transform(moving_data)#mapping.transform(affine_img.get_fdata())\n",
    "    save_nifti(os.path.join(dwi_path,output_name_base+'_aff_sym_forward.nii'),x_transformed,static_affine_original,static_img.header)\n",
    "    #\n",
    "    x_transformed_inv = mapping.transform_inverse(static,image_world2grid=static_affine)\n",
    "    x_affine_inv = affinemap.transform_inverse(x_transformed_inv, image_grid2world=mapping.prealign, sampling_grid_shape=moving_data.shape,\n",
    "                        sampling_grid2world=None, resample_only=False)\n",
    "    data_aff_sym_back = data_padding(moving_data_original,x_affine_inv)\n",
    "    save_nifti(os.path.join(dwi_path,output_name_base+'_aff_sym_backward.nii'),data_aff_sym_back,moving_affine_original,moving_img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_to_t2_transform_atlas(dwi_path,transform_file_path,atlas_path,dwi_name,reg_aff_name,sym_name,atlas_name,output_name_base):\n",
    "    '''\n",
    "    transform_dir: eighter 'forward' or 'backward';\n",
    "    '''\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from dipy.io.image import load_nifti,save_nifti\n",
    "    from dipy.align.imaffine import (AffineMap,\n",
    "                                    AffineRegistration)\n",
    "    from dipy.align import read_mapping,resample\n",
    "    import matplotlib.pylab as plt\n",
    "    atlas_data,atlas_affine = load_nifti(os.path.join(atlas_path,atlas_name),return_img=False)\n",
    "\n",
    "    static_data,static_affine_original,static_img = load_nifti(os.path.join(atlas_path,atlas_name),\n",
    "                                            return_img=True)\n",
    "    static_affine = np.eye(4)\n",
    "    static = np.squeeze(static_data[:,:,:])#*mask\n",
    "    static_grid2world = static_affine\n",
    "\n",
    "    save_nifti(os.path.join(atlas_path,'codomain_test.nii'),static,static_affine,static_img.header)\n",
    "    codomain_img = os.path.join(atlas_path,'codomain_test.nii')\n",
    "\n",
    "    # load moving data\n",
    "    moving_data_original, moving_affine_original, moving_img = load_nifti(os.path.join(dwi_path,dwi_name), return_img=True)\n",
    "    moving_affine = np.eye(4)\n",
    "    moving_data = np.squeeze(moving_data_original)+1-1\n",
    "\n",
    "    # padding\n",
    "    moving_data = data_padding(static,moving_data)\n",
    "\n",
    "    save_nifti(os.path.join(dwi_path,'domain_test.nii'),moving_data,moving_affine,moving_img.header)\n",
    "    domain_img = os.path.join(dwi_path,'domain_test.nii')\n",
    "    #mapping transform\n",
    "    roi_max = int(np.max(atlas_data))\n",
    "    print(roi_max)\n",
    "    atlas_all = np.zeros(moving_data_original.shape[0:3]+(roi_max+1,))\n",
    "    atlas_all_roi = np.zeros(moving_data_original.shape[0:3]+(roi_max+1,))\n",
    "    for i_atlas in np.arange(1,roi_max+1):\n",
    "        #\n",
    "        atlas_all_roi[...,i_atlas] = i_atlas\n",
    "        #\n",
    "        i_roi_mask = np.where(atlas_data==i_atlas,1,0)\n",
    "        prealign = np.loadtxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'.txt'))\n",
    "        affinemap = AffineMap(prealign, domain_grid_shape=moving_data.shape, domain_grid2world=moving_affine,\n",
    "                    codomain_grid_shape=static, codomain_grid2world=static_affine)\n",
    "        # affine reverse transform\n",
    "        affine_inv = affinemap.transform_inverse(i_roi_mask, image_grid2world=static_affine, sampling_grid_shape=moving_data.shape,\n",
    "                            sampling_grid2world=None, resample_only=False)\n",
    "        data_aff_back = data_padding(moving_data_original,affine_inv)\n",
    "        # If needs to save single roi, comment out this\n",
    "        # save_nifti(os.path.join(dwi_path,output_name_base+'_aff_backward_atlas_'+str(i_atlas)+'.nii'),data_aff_back,moving_affine_original,moving_img.header)\n",
    "        #\n",
    "        mapping_file = os.path.join(transform_file_path,output_name_base+sym_name)\n",
    "        prealign_mapping = np.loadtxt(os.path.join(transform_file_path,output_name_base+reg_aff_name+'_mapping.txt'))\n",
    "        mapping = read_mapping(mapping_file,domain_img,codomain_img,prealign_mapping)#prealign\n",
    "        #\n",
    "        x_transformed_inv = mapping.transform_inverse(i_roi_mask,image_world2grid=static_affine)\n",
    "        x_affine_inv = affinemap.transform_inverse(x_transformed_inv, image_grid2world=mapping.prealign, sampling_grid_shape=moving_data.shape,\n",
    "                            sampling_grid2world=None, resample_only=False)\n",
    "        data_aff_sym_back = data_padding(moving_data_original,x_affine_inv)\n",
    "        # If needs to save single roi, comment out this\n",
    "        # save_nifti(os.path.join(dwi_path,output_name_base+'_aff_sym_backward_atlas_'+str(i_atlas)+'.nii'),data_aff_sym_back,moving_affine_original,moving_img.header)\n",
    "        atlas_all[:,:,:,i_atlas] = data_aff_sym_back\n",
    "    #--\n",
    "    atlas_inv_final_ind = np.argmax(atlas_all,axis=-1)\n",
    "    atlas_inv_final = np.take_along_axis(atlas_all_roi, np.expand_dims(atlas_inv_final_ind, axis=-1), axis=-1)\n",
    "    save_nifti(os.path.join(dwi_path,output_name_base+'_aff_sym_backward_atlas.nii'),atlas_inv_final,moving_affine_original,moving_img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_resample(brain_path,data_in,data_out,zooms_new):\n",
    "    '''\n",
    "    '''\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from dipy.io.image import load_nifti, save_nifti\n",
    "    from dipy.segment.mask import applymask\n",
    "    from dipy.io import read_bvals_bvecs\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    from dipy.reconst.dti import TensorModel\n",
    "    from dipy.reconst.dti import TensorFit\n",
    "    from dipy.reconst.dti import color_fa\n",
    "    from tqdm.notebook import tqdm\n",
    "    from dipy.viz import regtools\n",
    "    import dipy.denoise.noise_estimate as ne\n",
    "    import nibabel as nib\n",
    "    from dipy.align.reslice import reslice\n",
    "    os.chdir(brain_path)        \n",
    "    data_prefix = data_in\n",
    "    dwi_file = os.path.join(brain_path,data_prefix) # 4D diffusion data file name\n",
    "    img_data,img_affine,img = load_nifti(dwi_file,return_img=True)\n",
    "    zooms_old = img.header.get_zooms()[:3]\n",
    "    new_zooms = zooms_new[0:3]\n",
    "    if len(img_data.shape) == 4:\n",
    "        test,affine_test = reslice(img_data[:,:,:,0], img_affine, zooms_old, new_zooms)\n",
    "        data_new = np.zeros(test.shape+(img_data.shape[-1],))\n",
    "        for i_slice in np.arange(img_data.shape[-1]):\n",
    "            data_new[:,:,:,i_slice], affine_new = reslice(img_data[:,:,:,i_slice], img_affine, zooms_old, new_zooms)\n",
    "    elif len(img_data.shape) == 3:\n",
    "        data_new,affine_test = reslice(img_data, img_affine, zooms_old, new_zooms)\n",
    "    else:\n",
    "        print('input file error!')\n",
    "    # img_resample = nib.Nifti1Image(data_new.astype(np.int16), np.eye(4))\n",
    "    # save_nifti_origin(input=img_resample.get_data(),output_name=data_out,type_output=np.int16,\n",
    "    #                   zooms=zooms_new)\n",
    "    img.header.set_zooms(zooms_new)\n",
    "    save_nifti(data_out, data_new, img_affine,hdr=img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_choose_vol(brain_path,data_in,vol_arr,data_out):\n",
    "    '''\n",
    "    '''\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from dipy.io.image import load_nifti, save_nifti\n",
    "    from dipy.segment.mask import applymask\n",
    "    from dipy.io import read_bvals_bvecs\n",
    "    from dipy.core.gradients import gradient_table\n",
    "    from dipy.reconst.dti import TensorModel\n",
    "    from dipy.reconst.dti import TensorFit\n",
    "    from dipy.reconst.dti import color_fa\n",
    "    from tqdm.notebook import tqdm\n",
    "    from dipy.viz import regtools\n",
    "    import dipy.denoise.noise_estimate as ne\n",
    "    import nibabel as nib\n",
    "    from dipy.align.reslice import reslice\n",
    "    os.chdir(brain_path)        \n",
    "    data_prefix = data_in\n",
    "    dwi_file = os.path.join(brain_path,data_prefix) # 4D diffusion data file name\n",
    "    img_data,img_affine,img = load_nifti(dwi_file,return_img=True)\n",
    "    save_nifti(data_out, img_data[:,:,:,vol_arr], img_affine,hdr=img.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_t22_xy(brain_path,input_name,flip_axis,output_path,output_name):\n",
    "    '''\n",
    "    '''\n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "    from dipy.io.image import load_nifti,save_nifti\n",
    "    import os\n",
    "\n",
    "    data_original, aff_original, img_original = load_nifti(os.path.join(brain_path,input_name),return_img=True)\n",
    "    data_new = np.flip(data_original,axis=flip_axis)\n",
    "    save_nifti(os.path.join(output_path,output_name), data_new, aff_original,hdr=img_original.header)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip T2w along x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "flip_t22_xy(brain_path,input_name='T2w.nii',flip_axis=0,\n",
    "            output_path=brain_path,\n",
    "            output_name='T2w_brain_flip_x.nii')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dwi to b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "dwi_to_b0(dwi_path=brain_path,dwi_name='dwi_topuped',b_prefix='dwi_mb0',\n",
    "          output_name='dwi_to_b0',b_output_name='dwi_to_b0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample dwi to isotropic one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "dwi_resample(brain_path,data_in='dwi_to_b0.nii',data_out='dwi_iso.nii',zooms_new=[1.5,1.5,1.5,8])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resampling b0 to t2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "brain_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "dwi_resample(brain_path,data_in='dwi_iso.nii',data_out='dwi_iso_resampled.nii',zooms_new=[1.0,1.0,1.0,8])\n",
    "dwi_resample(brain_path,data_in='T2w_brain_flip_x.nii',data_out='T2_resampled.nii',zooms_new=[1.0,1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "data_in = 'dwi_iso_resampled.nii'\n",
    "vol_arr = [0]\n",
    "data_out = 'dwi_iso_resampled_b0.nii'\n",
    "dwi_choose_vol(brain_path,data_in,vol_arr,data_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dwi to t2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dwi_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "t2w_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "transform_file_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "dwi_name = 'dwi_iso_resampled_b0_brain.nii.gz'\n",
    "t2w_name = 'T2w_resampled_brain.nii.gz'\n",
    "b_input_name = 'dwi_to_b0'\n",
    "reg_aff_name = '_aff'\n",
    "sym_name = '_aff_sym.nii'\n",
    "output_name_base = 'b0_to_t2w'\n",
    "dwi_to_t2(dwi_path,t2w_path,transform_file_path,dwi_name,t2w_name,b_input_name,reg_aff_name,sym_name,output_name_base)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "t2w_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "transform_file_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "dwi_name = 'dwi_iso_resampled_b0_brain.nii.gz'\n",
    "t2w_name = 'T2w_resampled_brain.nii.gz'\n",
    "reg_aff_name = '_aff'\n",
    "sym_name = '_aff_sym.nii'\n",
    "output_name_base = 'b0_to_t2w'\n",
    "transform_dir = 'forward'\n",
    "\n",
    "dwi_to_t2_transform(dwi_path,t2w_path,transform_file_path,dwi_name,t2w_name,reg_aff_name,sym_name,output_name_base,transform_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling back to dwi original resolution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ROI atlas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer ROI back to subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "atlas_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "transform_file_path = '/media/erjun/One_Touch/Newborns/sub-B027S1/ses-01/Registration_test'\n",
    "dwi_name = 'dwi_iso_resampled_b0_brain.nii.gz'\n",
    "atlas_name = 'T2w_brain_atlas.nii.gz'\n",
    "reg_aff_name = '_aff'\n",
    "sym_name = '_aff_sym.nii'\n",
    "output_name_base = 'b0_to_t2w'\n",
    "dwi_to_t2_transform_atlas(dwi_path,transform_file_path,atlas_path,dwi_name,reg_aff_name,sym_name,atlas_name,output_name_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6a818820a2d4b94df252b23f7d311b5b1a3798c769b2a454cee3c1911e726f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
